{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bigru_sampled_softmax.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [
        {
          "file_id": "1Ql9_dY8UIyvvogmQRTK4CbLArFLrekea",
          "timestamp": 1524337877520
        },
        {
          "file_id": "1cFawdk2WN_V9253Qa3U1FEE4UTQ0F0cT",
          "timestamp": 1523598741746
        },
        {
          "file_id": "1q1FnNWLBKP2viJPFYLkinhLkuk1IewZ1",
          "timestamp": 1523446951674
        },
        {
          "file_id": "1vk2vgCL6Hm0xwpuQwYu2ff9_V9YLCo4s",
          "timestamp": 1522867289647
        },
        {
          "file_id": "1jzpP0z0UQdmGwiKkStsVX3QkjsWn53Ek",
          "timestamp": 1522306429357
        }
      ],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "JUET7sqfos6T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Example of Sequence-to-Sequence with sampled softmax"
      ]
    },
    {
      "metadata": {
        "id": "FTocuRmsozMT",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "#__author__ = \"@inimah\"\n",
        "#__date__ = \"21.04.2018\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CsedGWmOVInh",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Install Keras with pip\n",
        "!pip install -q keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CXzXhG9ECDWS",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "14cd107a-7416-4044-a37a-8321b9510025",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524340030157,
          "user_tz": -120,
          "elapsed": 1428,
          "user": {
            "displayName": "Iftitahu Nimah",
            "photoUrl": "//lh5.googleusercontent.com/-2H8SGwD_zvc/AAAAAAAAAAI/AAAAAAAAPGY/qh04HjJj8ZQ/s50-c-k-no/photo.jpg",
            "userId": "111575679600498524578"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "keras.__version__"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.1.5'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "M_XEETgwoHBu",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import nltk\n",
        "import string\n",
        "from string import punctuation\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xa9973wxoGCM",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import _pickle as cPickle\n",
        "\n",
        "# reading file in pickle format\n",
        "def readPickle(pickleFilename):\n",
        "\tf = open(pickleFilename, 'rb')\n",
        "\tobj = cPickle.load(f)\n",
        "\tf.close()\n",
        "\treturn obj\n",
        "\n",
        "def savePickle(dataToWrite,pickleFilename):\n",
        "\tf = open(pickleFilename, 'wb')\n",
        "\tcPickle.dump(dataToWrite, f)\n",
        "\tf.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LTys2vk6oZOL",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "local_download_path = os.path.expanduser('~/datatita')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NWKM9MwSo_ij",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Reading preprocessed data"
      ]
    },
    {
      "metadata": {
        "id": "CUsfz9hJWMro",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "wiki_doc_topics = readPickle(os.path.join(local_download_path,'wiki_doc_topics.pkl'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8JnMXPdbatq8",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "train_docs = readPickle(os.path.join(local_download_path,'wiki_train_docs_bigru.pkl'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aJxiuPnAa4bu",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "train_keyphrases = readPickle(os.path.join(local_download_path,'wiki_train_keyphrases_bigru.pkl'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K7d1keTl163B",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "train_docids = readPickle(os.path.join(local_download_path,'wiki_train_docids_bigru.pkl'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O4J98xfArp7l",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Tokenization and vocabulary indexing"
      ]
    },
    {
      "metadata": {
        "id": "lRAINxdSPbJ_",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "unlisted_punct = ['-', '_', '+', '#']\n",
        "punct = ''.join([p for p in string.punctuation if p not in unlisted_punct])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Oj4WAsIbrty9",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import re\n",
        "def tokenizeWords(text):\n",
        "  \n",
        "  regex = re.compile('[%s]' % re.escape(punct))\n",
        "  clean_text = regex.sub('', text)\n",
        "  #clean_text = re.sub(r\"[\\-\\+\\_]+\\ *\", \" \", clean_text)\n",
        "  clean_text = re.sub(r\"[\\-\\_]+\\ *\", \" \", clean_text)\n",
        "  tokens = clean_text.split()\n",
        "  \n",
        "  return [t.lower() for t in tokens]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q6p_j48cYeiH",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def clean_keyphrases(keyphrase_list):\n",
        "  \n",
        "  kp_list = []\n",
        "  \n",
        "  for kp in keyphrase_list:\n",
        "    \n",
        "    regex = re.compile('[%s]' % re.escape(punct))\n",
        "    text = regex.sub('', kp)\n",
        "    #text = re.sub(r\"[\\-\\+\\_]+\\ *\", \" \", text)\n",
        "    text = re.sub(r\"[\\-\\_]+\\ *\", \" \", text)\n",
        "    text = text.lower()\n",
        "    \n",
        "    kp_list.append(text)\n",
        "\n",
        "  return kp_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k02zUaZ5ruoW",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def indexingVocabulary(array_of_words):\n",
        "    \n",
        "    # frequency of word across document corpus\n",
        "    tf = nltk.FreqDist(array_of_words)\n",
        "    wordIndex = list(tf.keys())\n",
        "    \n",
        "    wordIndex.insert(0,'<pad>')\n",
        "    wordIndex.append('<start>')\n",
        "    wordIndex.append('<end>')\n",
        "    wordIndex.append('<unk>')\n",
        "    # indexing word vocabulary : pairs of (index,word)\n",
        "    vocab=dict([(i,wordIndex[i]) for i in range(len(wordIndex))])\n",
        "    \n",
        "    return vocab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HTcJ6k5Fk9Jw",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "all_words = []\n",
        "tokenized_train_docs = []\n",
        "tokenized_train_keyphrases = []\n",
        "\n",
        "for doc in train_docs:\n",
        "  all_words.extend(tokenizeWords(doc))\n",
        "  tokenized_train_docs.append(tokenizeWords(doc))\n",
        "   \n",
        "      \n",
        "for keyphrase in train_keyphrases:\n",
        "  all_words.extend(tokenizeWords(keyphrase))\n",
        "  tokenized_train_keyphrases.append(tokenizeWords(keyphrase))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MXmvA9cfl29V",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "term_freq = nltk.FreqDist(all_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rZXrGvNYl9P9",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d139d98a-2734-475b-a0c2-28045cdd9562",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524340044764,
          "user_tz": -120,
          "elapsed": 402,
          "user": {
            "displayName": "Iftitahu Nimah",
            "photoUrl": "//lh5.googleusercontent.com/-2H8SGwD_zvc/AAAAAAAAAAI/AAAAAAAAPGY/qh04HjJj8ZQ/s50-c-k-no/photo.jpg",
            "userId": "111575679600498524578"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"unique words in corpus in descending order (according to their frequency): %s\"%str(len(term_freq)))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "unique words in corpus in descending order (according to their frequency): 7641\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "P5Dz7pjRmKqq",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "common_words = term_freq.most_common(len(term_freq))\n",
        "arr_common = np.array(common_words)\n",
        "words = arr_common[:,0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P5nLskbLmOC4",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "indices_words = indexingVocabulary(words)\n",
        "words_indices = dict((v,k) for (k,v) in indices_words.items())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kkOAL9dCbvPo",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5d64ab9e-6e13-4e18-8253-342c00fdc015",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524340047409,
          "user_tz": -120,
          "elapsed": 696,
          "user": {
            "displayName": "Iftitahu Nimah",
            "photoUrl": "//lh5.googleusercontent.com/-2H8SGwD_zvc/AAAAAAAAAAI/AAAAAAAAPGY/qh04HjJj8ZQ/s50-c-k-no/photo.jpg",
            "userId": "111575679600498524578"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"vocabulary size: %s\"%str(len(indices_words)))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocabulary size: 7645\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "H3pYeNzJpsQf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Preparing training and validation set"
      ]
    },
    {
      "metadata": {
        "id": "fsKPc7jaOx9J",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kj5UJvZppE6L",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "encoder_length = 300 # maximum sequence length (number of words) in encoder layer\n",
        "decoder_length = 5 # maximum sequence length (number of words) in decoder layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PXo8tB2_px4D",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Transforming data into integer format of X, Y sequences"
      ]
    },
    {
      "metadata": {
        "id": "zOsRmL_zqRZy",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "X = np.zeros((len(tokenized_train_docs), encoder_length), dtype=np.int32) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "64dKJAmzqsfg",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "y_in = np.zeros((len(tokenized_train_docs), decoder_length+1), dtype=np.int32) \n",
        "y_out = np.zeros((len(tokenized_train_docs), decoder_length+1), dtype=np.int32) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AEEV3pi6ue2s",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "for i, doc in enumerate(tokenized_train_docs):\n",
        "    \n",
        "    len_doc = len(doc)\n",
        "    if len_doc > encoder_length:\n",
        "      txt = doc[:encoder_length]\n",
        "    else:\n",
        "      txt = doc\n",
        "    for t, word in enumerate(txt):\n",
        "      X[i, t] = words_indices[word]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9XLuQobqwE9h",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "for i, doc in enumerate(tokenized_train_keyphrases):\n",
        "  \n",
        "    len_doc = len(doc)\n",
        "    \n",
        "    if len_doc > decoder_length:\n",
        "        txt = doc[:decoder_length]\n",
        "    else:\n",
        "        txt = doc\n",
        "        \n",
        "    txt_in = list(txt)\n",
        "    txt_out = list(txt)\n",
        "    \n",
        "    txt_in.insert(0,'<start>')\n",
        "    txt_out.append('<end>')\n",
        "    \n",
        "    for j, word in enumerate(txt_in):\n",
        "        y_in[i, j] = words_indices[word]\n",
        "        \n",
        "    for j, word in enumerate(txt_out):\n",
        "        y_out[i, j] = words_indices[word]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CylgqucZ11SV",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# shuffling the order of data pairs (randomize permutation is stored to be reusable)\n",
        "rand_ids = readPickle(os.path.join(local_download_path,'rand_idx_train'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "enc0NUHo9DHt",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "X_train = []\n",
        "y_train_in = []\n",
        "y_train_out = []\n",
        "X_valid = []\n",
        "y_valid_in = []\n",
        "y_valid_out = []\n",
        "\n",
        "n_train = int(0.8 * X.shape[0])\n",
        "for i, idx in enumerate(rand_ids):\n",
        "  if i < n_train:\n",
        "    X_train.append(X[idx])\n",
        "    y_train_in.append(y_in[idx])\n",
        "    y_train_out.append(y_out[idx])\n",
        "  else:\n",
        "    X_valid.append(X[idx])\n",
        "    y_valid_in.append(y_in[idx])\n",
        "    y_valid_out.append(y_out[idx])\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0BhiS_a4_aBa",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "X_train = np.array(X_train)\n",
        "y_train_in = np.array(y_train_in)\n",
        "y_train_out = np.array(y_train_out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YnaOhOO1_goB",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "X_valid = np.array(X_valid)\n",
        "y_valid_in = np.array(y_valid_in)\n",
        "y_valid_out = np.array(y_valid_out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jTtxZ1jvsvOi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Model"
      ]
    },
    {
      "metadata": {
        "id": "HlGO0WlR_rrw",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Embedding\n",
        "from keras.layers import LSTM, GRU, concatenate\n",
        "from keras.layers import Dense, Lambda, Reshape\n",
        "import keras.backend as K\n",
        "from keras.models import load_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZtETEoZjqby1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Encoder model"
      ]
    },
    {
      "metadata": {
        "id": "sJhMw8Re_z_v",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# encoder input (a whole text without splitting into sentences)\n",
        "in_encoder = Input(shape=(encoder_length,), dtype='int32', name='encoder-input')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IUNHcsHz_6wR",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "enc_embedding = Embedding(len(indices_words), 100, input_length=encoder_length, name='embedding_encoder')\n",
        "input_embedded = enc_embedding(in_encoder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tMo9P2RdwazK",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "fwd_encoder = GRU(128, return_state=True, name='fwd-encoder')\n",
        "bwd_encoder = GRU(128, return_state=True, name='bwd-encoder', go_backwards=True)\n",
        "encoder_outputs_1, state_h_1 = fwd_encoder(input_embedded)\n",
        "encoder_outputs_2, state_h_2 = bwd_encoder(input_embedded)\n",
        "bidir_encoder_out = concatenate([encoder_outputs_1, encoder_outputs_2],axis=-1)\n",
        "bidir_encoder_state = concatenate([state_h_1, state_h_2],axis=-1)\n",
        "\n",
        "bidir_encoder = [bidir_encoder_out, bidir_encoder_state]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AkagcvnKiLIL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Sampling class (sampled softmax)"
      ]
    },
    {
      "metadata": {
        "id": "2L0wOUsxqkEZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "modified to hold true when operating in 3D sequences"
      ]
    },
    {
      "metadata": {
        "id": "qmqb-74TiKhA",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Layer\n",
        "class SamplingLayer(Layer):\n",
        "    def __init__(self, num_sampled, num_classes, mode, **kwargs):\n",
        "        self.num_sampled = num_sampled\n",
        "        self.num_classes = num_classes\n",
        "        self.mode = mode\n",
        "        super(SamplingLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        dense_shape, classes_shape = input_shape\n",
        "        self.kernel = self.add_weight(name='kernel',\n",
        "                                      shape=(self.num_classes, dense_shape[1]),\n",
        "                                      initializer='uniform',\n",
        "                                      trainable=True)\n",
        "        self.bias = self.add_weight(name='bias',\n",
        "                                      shape=(self.num_classes,),\n",
        "                                      initializer='uniform',\n",
        "                                      trainable=True)  \n",
        "\n",
        "        super(SamplingLayer, self).build(input_shape)  \n",
        "\n",
        "    def call(self, inputs_and_labels):\n",
        "        inputs, labels = inputs_and_labels\n",
        "        if self.mode == \"train\":\n",
        "            loss = tf.nn.sampled_softmax_loss(\n",
        "                weights=self.kernel,\n",
        "                biases=self.bias,\n",
        "                labels=labels,\n",
        "                inputs=inputs,\n",
        "                num_sampled=self.num_sampled,\n",
        "                num_classes=self.num_classes,\n",
        "                num_true=1)\n",
        "\n",
        "        elif self.mode == \"eval\":\n",
        "            logits = tf.matmul(inputs, tf.transpose(self.kernel))\n",
        "            logits = tf.nn.bias_add(logits, self.bias)\n",
        "            labels_one_hot = tf.one_hot(labels, self.num_classes)\n",
        "            loss = tf.nn.softmax_cross_entropy_with_logits_v2(\n",
        "                labels=labels_one_hot,\n",
        "                logits=logits)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        dense_shape, classes_shape = input_shape\n",
        "        return (dense_shape[0], self.num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JBlB5GnwiaVq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Decoder model with sampled softmax"
      ]
    },
    {
      "metadata": {
        "id": "aWkvccNBidXQ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "in_decoder = Input(shape=(None, ), name='decoder-input', dtype='int32')\n",
        "dec_embedding = Embedding(len(indices_words), 100, name='embedding_decoder')\n",
        "dec_input_embedded = dec_embedding(in_decoder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oHuD0q8EjVdo",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "labels = Input((decoder_length+1,1), dtype='int32', name='labels_')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4X5DeeQvijra",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "f400de89-72df-4111-adc2-49e234a3826e",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524340063489,
          "user_tz": -120,
          "elapsed": 1733,
          "user": {
            "displayName": "Iftitahu Nimah",
            "photoUrl": "//lh5.googleusercontent.com/-2H8SGwD_zvc/AAAAAAAAAAI/AAAAAAAAPGY/qh04HjJj8ZQ/s50-c-k-no/photo.jpg",
            "userId": "111575679600498524578"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "fwd_decoder = GRU(256, return_sequences=True, return_state=True, name='fwd-decoder')\n",
        "dec_outputs, dec_state_h = fwd_decoder(dec_input_embedded, initial_state=bidir_encoder_state)\n",
        "\n",
        "\n",
        "losses = []\n",
        "for t in range(decoder_length+1):\n",
        "  dec_outputs_t = Lambda(lambda x: dec_outputs[:,t,:], name='dec_out-%s'%t)(dec_outputs)\n",
        "  label_t = Lambda(lambda x: labels[:,t,:], name='label-%s'%t)(labels)\n",
        "  loss = SamplingLayer(500, len(indices_words), mode='train', name='sampled_layer-%s'%t)([dec_outputs_t, label_t])\n",
        "  losses.append(loss)\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:1344: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-eE9crSdjqJ7",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model = Model(inputs=[in_encoder, in_decoder, labels], outputs=losses)\n",
        "model.compile(loss=lambda y_true, loss: loss, optimizer='rmsprop')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RUyZ-jx9jvbl",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 1190
        },
        "outputId": "f4e719c6-455c-49d3-b359-e9d68febe7d1",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524340064720,
          "user_tz": -120,
          "elapsed": 493,
          "user": {
            "displayName": "Iftitahu Nimah",
            "photoUrl": "//lh5.googleusercontent.com/-2H8SGwD_zvc/AAAAAAAAAAI/AAAAAAAAPGY/qh04HjJj8ZQ/s50-c-k-no/photo.jpg",
            "userId": "111575679600498524578"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "encoder-input (InputLayer)      (None, 300)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_encoder (Embedding)   (None, 300, 100)     764500      encoder-input[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder-input (InputLayer)      (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "fwd-encoder (GRU)               [(None, 128), (None, 87936       embedding_encoder[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "bwd-encoder (GRU)               [(None, 128), (None, 87936       embedding_encoder[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "embedding_decoder (Embedding)   (None, None, 100)    764500      decoder-input[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 256)          0           fwd-encoder[0][1]                \n",
            "                                                                 bwd-encoder[0][1]                \n",
            "__________________________________________________________________________________________________\n",
            "fwd-decoder (GRU)               [(None, None, 256),  274176      embedding_decoder[0][0]          \n",
            "                                                                 concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "labels_ (InputLayer)            (None, 6, 1)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dec_out-0 (Lambda)              (None, 256)          0           fwd-decoder[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "label-0 (Lambda)                (None, 1)            0           labels_[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dec_out-1 (Lambda)              (None, 256)          0           fwd-decoder[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "label-1 (Lambda)                (None, 1)            0           labels_[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dec_out-2 (Lambda)              (None, 256)          0           fwd-decoder[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "label-2 (Lambda)                (None, 1)            0           labels_[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dec_out-3 (Lambda)              (None, 256)          0           fwd-decoder[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "label-3 (Lambda)                (None, 1)            0           labels_[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dec_out-4 (Lambda)              (None, 256)          0           fwd-decoder[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "label-4 (Lambda)                (None, 1)            0           labels_[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dec_out-5 (Lambda)              (None, 256)          0           fwd-decoder[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "label-5 (Lambda)                (None, 1)            0           labels_[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "sampled_layer-0 (SamplingLayer) (None, 7645)         1964765     dec_out-0[0][0]                  \n",
            "                                                                 label-0[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "sampled_layer-1 (SamplingLayer) (None, 7645)         1964765     dec_out-1[0][0]                  \n",
            "                                                                 label-1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "sampled_layer-2 (SamplingLayer) (None, 7645)         1964765     dec_out-2[0][0]                  \n",
            "                                                                 label-2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "sampled_layer-3 (SamplingLayer) (None, 7645)         1964765     dec_out-3[0][0]                  \n",
            "                                                                 label-3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "sampled_layer-4 (SamplingLayer) (None, 7645)         1964765     dec_out-4[0][0]                  \n",
            "                                                                 label-4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "sampled_layer-5 (SamplingLayer) (None, 7645)         1964765     dec_out-5[0][0]                  \n",
            "                                                                 label-5[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 13,767,638\n",
            "Trainable params: 13,767,638\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1NR13oRPkDYQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Train sampled softmax"
      ]
    },
    {
      "metadata": {
        "id": "FzNBfIhJkWRQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Transform y_true labels to one hot encoding"
      ]
    },
    {
      "metadata": {
        "id": "MBuN-ecDkvCa",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "620a4ae0-6c66-4bf7-dab8-28b8fed35cd7",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524340065477,
          "user_tz": -120,
          "elapsed": 483,
          "user": {
            "displayName": "Iftitahu Nimah",
            "photoUrl": "//lh5.googleusercontent.com/-2H8SGwD_zvc/AAAAAAAAAAI/AAAAAAAAPGY/qh04HjJj8ZQ/s50-c-k-no/photo.jpg",
            "userId": "111575679600498524578"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "y_train_out.shape"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(568, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "metadata": {
        "id": "qGxC_4LVkVUq",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "y_decoder_train_out = to_categorical(y_train_out, len(indices_words))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "znK3qv7WkI2q",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "047e9407-d08a-4857-862a-75b39dd06d8b",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524340067131,
          "user_tz": -120,
          "elapsed": 426,
          "user": {
            "displayName": "Iftitahu Nimah",
            "photoUrl": "//lh5.googleusercontent.com/-2H8SGwD_zvc/AAAAAAAAAAI/AAAAAAAAPGY/qh04HjJj8ZQ/s50-c-k-no/photo.jpg",
            "userId": "111575679600498524578"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "y_decoder_train_out.shape"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(568, 6, 7645)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "metadata": {
        "id": "GFp8Acdbk6Da",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# reshape y to 3D dimension (batch_size, sequence_length, 1)\n",
        "y = y_train_out.reshape((y_train_out.shape[0], y_train_out.shape[1], 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5zU_2A2blARg",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a20e2281-6f3b-4591-cc52-e4e68c35faa8",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524340069254,
          "user_tz": -120,
          "elapsed": 477,
          "user": {
            "displayName": "Iftitahu Nimah",
            "photoUrl": "//lh5.googleusercontent.com/-2H8SGwD_zvc/AAAAAAAAAAI/AAAAAAAAPGY/qh04HjJj8ZQ/s50-c-k-no/photo.jpg",
            "userId": "111575679600498524578"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(568, 6, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "metadata": {
        "id": "9eN0ePFilGgD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "swap axis of one hot encoded y_labels since the output of our sampled-softmax model is a list from decoder time steps"
      ]
    },
    {
      "metadata": {
        "id": "ibeixTC2lB75",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "outputs = list(y_decoder_train_out.swapaxes(0,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mOrR2fGMudVi",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5ad6da7e-c25f-4bb4-877d-53eca5c72c64",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524340070828,
          "user_tz": -120,
          "elapsed": 464,
          "user": {
            "displayName": "Iftitahu Nimah",
            "photoUrl": "//lh5.googleusercontent.com/-2H8SGwD_zvc/AAAAAAAAAAI/AAAAAAAAPGY/qh04HjJj8ZQ/s50-c-k-no/photo.jpg",
            "userId": "111575679600498524578"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "np.array(outputs).shape"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 568, 7645)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "metadata": {
        "id": "JJh_a0a-lTDb",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "4e7e0b58-f038-48d3-c1a2-e143935d7b57",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524340381212,
          "user_tz": -120,
          "elapsed": 310120,
          "user": {
            "displayName": "Iftitahu Nimah",
            "photoUrl": "//lh5.googleusercontent.com/-2H8SGwD_zvc/AAAAAAAAAAI/AAAAAAAAPGY/qh04HjJj8ZQ/s50-c-k-no/photo.jpg",
            "userId": "111575679600498524578"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit([X_train, y_train_in, y], outputs, validation_split=0.2, batch_size=32, epochs=10)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 454 samples, validate on 114 samples\n",
            "Epoch 1/10\n",
            "454/454 [==============================] - 33s 73ms/step - loss: 29.8692 - sampled_layer-0_loss: 6.8026 - sampled_layer-1_loss: 5.8478 - sampled_layer-2_loss: 4.2852 - sampled_layer-3_loss: 4.3336 - sampled_layer-4_loss: 4.4035 - sampled_layer-5_loss: 4.1965 - val_loss: 14.8907 - val_sampled_layer-0_loss: 6.7690 - val_sampled_layer-1_loss: 4.2783 - val_sampled_layer-2_loss: 2.1102 - val_sampled_layer-3_loss: 0.8994 - val_sampled_layer-4_loss: 0.4662 - val_sampled_layer-5_loss: 0.3677\n",
            "Epoch 2/10\n",
            "454/454 [==============================] - 31s 68ms/step - loss: 12.7507 - sampled_layer-0_loss: 5.6426 - sampled_layer-1_loss: 4.1291 - sampled_layer-2_loss: 1.8537 - sampled_layer-3_loss: 0.6412 - sampled_layer-4_loss: 0.3008 - sampled_layer-5_loss: 0.1832 - val_loss: 13.2601 - val_sampled_layer-0_loss: 6.5698 - val_sampled_layer-1_loss: 3.9164 - val_sampled_layer-2_loss: 1.9225 - val_sampled_layer-3_loss: 0.6602 - val_sampled_layer-4_loss: 0.1230 - val_sampled_layer-5_loss: 0.0681\n",
            "Epoch 3/10\n",
            "454/454 [==============================] - 30s 67ms/step - loss: 10.7312 - sampled_layer-0_loss: 4.9735 - sampled_layer-1_loss: 3.5216 - sampled_layer-2_loss: 1.5631 - sampled_layer-3_loss: 0.4781 - sampled_layer-4_loss: 0.1345 - sampled_layer-5_loss: 0.0605 - val_loss: 13.3339 - val_sampled_layer-0_loss: 6.4079 - val_sampled_layer-1_loss: 3.8754 - val_sampled_layer-2_loss: 2.3659 - val_sampled_layer-3_loss: 0.6132 - val_sampled_layer-4_loss: 0.0465 - val_sampled_layer-5_loss: 0.0250\n",
            "Epoch 4/10\n",
            "454/454 [==============================] - 31s 68ms/step - loss: 9.6907 - sampled_layer-0_loss: 4.5236 - sampled_layer-1_loss: 3.2373 - sampled_layer-2_loss: 1.3830 - sampled_layer-3_loss: 0.4249 - sampled_layer-4_loss: 0.0895 - sampled_layer-5_loss: 0.0323 - val_loss: 13.0023 - val_sampled_layer-0_loss: 6.5179 - val_sampled_layer-1_loss: 3.9546 - val_sampled_layer-2_loss: 1.8376 - val_sampled_layer-3_loss: 0.6560 - val_sampled_layer-4_loss: 0.0229 - val_sampled_layer-5_loss: 0.0132\n",
            "Epoch 5/10\n",
            "416/454 [==========================>...] - ETA: 2s - loss: 9.2669 - sampled_layer-0_loss: 4.2272 - sampled_layer-1_loss: 3.0223 - sampled_layer-2_loss: 1.3239 - sampled_layer-3_loss: 0.3847 - sampled_layer-4_loss: 0.2857 - sampled_layer-5_loss: 0.0230"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "454/454 [==============================] - 31s 68ms/step - loss: 9.4268 - sampled_layer-0_loss: 4.3181 - sampled_layer-1_loss: 3.1533 - sampled_layer-2_loss: 1.2825 - sampled_layer-3_loss: 0.3871 - sampled_layer-4_loss: 0.2640 - sampled_layer-5_loss: 0.0217 - val_loss: 13.3605 - val_sampled_layer-0_loss: 6.8208 - val_sampled_layer-1_loss: 3.9746 - val_sampled_layer-2_loss: 1.8973 - val_sampled_layer-3_loss: 0.6418 - val_sampled_layer-4_loss: 0.0206 - val_sampled_layer-5_loss: 0.0054\n",
            "Epoch 6/10\n",
            "454/454 [==============================] - 30s 66ms/step - loss: 8.6672 - sampled_layer-0_loss: 4.0290 - sampled_layer-1_loss: 2.9980 - sampled_layer-2_loss: 1.1933 - sampled_layer-3_loss: 0.3594 - sampled_layer-4_loss: 0.0723 - sampled_layer-5_loss: 0.0151 - val_loss: 13.6466 - val_sampled_layer-0_loss: 6.8333 - val_sampled_layer-1_loss: 4.1686 - val_sampled_layer-2_loss: 1.9852 - val_sampled_layer-3_loss: 0.6401 - val_sampled_layer-4_loss: 0.0150 - val_sampled_layer-5_loss: 0.0044\n",
            "Epoch 7/10\n",
            "454/454 [==============================] - 30s 67ms/step - loss: 9.6357 - sampled_layer-0_loss: 4.1621 - sampled_layer-1_loss: 2.9227 - sampled_layer-2_loss: 1.3588 - sampled_layer-3_loss: 0.9682 - sampled_layer-4_loss: 0.2137 - sampled_layer-5_loss: 0.0102 - val_loss: 13.8257 - val_sampled_layer-0_loss: 6.9952 - val_sampled_layer-1_loss: 4.1614 - val_sampled_layer-2_loss: 1.9715 - val_sampled_layer-3_loss: 0.6692 - val_sampled_layer-4_loss: 0.0258 - val_sampled_layer-5_loss: 0.0026\n",
            "Epoch 8/10\n",
            "454/454 [==============================] - 30s 66ms/step - loss: 8.0511 - sampled_layer-0_loss: 3.9574 - sampled_layer-1_loss: 2.6190 - sampled_layer-2_loss: 1.0672 - sampled_layer-3_loss: 0.3323 - sampled_layer-4_loss: 0.0683 - sampled_layer-5_loss: 0.0069 - val_loss: 13.9892 - val_sampled_layer-0_loss: 6.9609 - val_sampled_layer-1_loss: 4.3233 - val_sampled_layer-2_loss: 2.0276 - val_sampled_layer-3_loss: 0.6607 - val_sampled_layer-4_loss: 0.0152 - val_sampled_layer-5_loss: 0.0015\n",
            "Epoch 9/10\n",
            "454/454 [==============================] - 30s 66ms/step - loss: 7.9493 - sampled_layer-0_loss: 3.8232 - sampled_layer-1_loss: 2.6966 - sampled_layer-2_loss: 1.0593 - sampled_layer-3_loss: 0.3011 - sampled_layer-4_loss: 0.0564 - sampled_layer-5_loss: 0.0127 - val_loss: 14.6932 - val_sampled_layer-0_loss: 6.9603 - val_sampled_layer-1_loss: 5.0562 - val_sampled_layer-2_loss: 2.0289 - val_sampled_layer-3_loss: 0.6356 - val_sampled_layer-4_loss: 0.0117 - val_sampled_layer-5_loss: 4.8633e-04\n",
            "Epoch 10/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "454/454 [==============================] - 30s 66ms/step - loss: 8.1677 - sampled_layer-0_loss: 3.8740 - sampled_layer-1_loss: 2.9501 - sampled_layer-2_loss: 0.9978 - sampled_layer-3_loss: 0.2705 - sampled_layer-4_loss: 0.0496 - sampled_layer-5_loss: 0.0258 - val_loss: 14.5795 - val_sampled_layer-0_loss: 7.4753 - val_sampled_layer-1_loss: 4.4831 - val_sampled_layer-2_loss: 1.9461 - val_sampled_layer-3_loss: 0.6651 - val_sampled_layer-4_loss: 0.0097 - val_sampled_layer-5_loss: 3.3438e-04\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff375ffec18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    }
  ]
}